# LinearLeap
## Intro
This is just a classic gradient descent algorithm.
I used the random normal function form numpy to great the regression

## Report
My algorithm seems to work well.
We can see that it uses 1000 iterations but it could use only ~350
I used the least squares method to calculate the performance.
So it can be observed that it usually works pretty well, with determining coefficient between 99% and 90%.

But sometimes it is completely weird and gives something low like 50%, but it is probably due to my high learning rate (0.01)
